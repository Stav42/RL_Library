WandB initialization done
Arguments passed to the script:
exp_name: 10-Oct-2023
gym_id: InvertedPendulum-v4
learning_rate: 0.00025
seed: 1
track: True
wandb_project_name: Prototype
wandb_entity: None
num_minibatches: 32
num_envs: 8
total_timesteps: 100000
num_steps: 800
update_epochs: 3
description: wandblogging
anneal_lr: True
batch_size: 6400
minibatch_size: 200
Start training
WandB Project Name:  Prototype
(8, 4)
Update:  1
rollout steps: 6400 time taken overall 3.814697265625e-06 time taken per step: 1.4901161193847657e-10
Epoch|Batch:  0 | 0
Epoch|Batch:  0 | 1
Epoch|Batch:  0 | 2
Epoch|Batch:  0 | 3
Epoch|Batch:  0 | 4
Epoch|Batch:  0 | 5
Epoch|Batch:  0 | 6
Epoch|Batch:  0 | 7
Epoch|Batch:  0 | 8
Epoch|Batch:  0 | 9
Epoch|Batch:  0 | 10
Epoch|Batch:  0 | 11
Epoch|Batch:  0 | 12
Epoch|Batch:  0 | 13
Epoch|Batch:  0 | 14
Epoch|Batch:  0 | 15
Epoch|Batch:  0 | 16
Epoch|Batch:  0 | 17
Epoch|Batch:  0 | 18
Epoch|Batch:  0 | 19
Epoch|Batch:  0 | 20
Epoch|Batch:  0 | 21
Epoch|Batch:  0 | 22
Epoch|Batch:  0 | 23
Epoch|Batch:  0 | 24
Epoch|Batch:  0 | 25
Epoch|Batch:  0 | 26
Epoch|Batch:  0 | 27
Epoch|Batch:  0 | 28
Epoch|Batch:  0 | 29
Epoch|Batch:  0 | 30
Epoch|Batch:  0 | 31
Epoch|Batch:  1 | 0
Epoch|Batch:  1 | 1
Epoch|Batch:  1 | 2
Epoch|Batch:  1 | 3
Epoch|Batch:  1 | 4
Epoch|Batch:  1 | 5
Epoch|Batch:  1 | 6
Epoch|Batch:  1 | 7
Epoch|Batch:  1 | 8
Epoch|Batch:  1 | 9
Epoch|Batch:  1 | 10
Epoch|Batch:  1 | 11
Epoch|Batch:  1 | 12
Epoch|Batch:  1 | 13
Epoch|Batch:  1 | 14
Epoch|Batch:  1 | 15
Epoch|Batch:  1 | 16
Epoch|Batch:  1 | 17
Epoch|Batch:  1 | 18
Epoch|Batch:  1 | 19
Epoch|Batch:  1 | 20
Epoch|Batch:  1 | 21
Epoch|Batch:  1 | 22
Epoch|Batch:  1 | 23
Epoch|Batch:  1 | 24
Epoch|Batch:  1 | 25
Epoch|Batch:  1 | 26
Epoch|Batch:  1 | 27
Epoch|Batch:  1 | 28
Epoch|Batch:  1 | 29
Epoch|Batch:  1 | 30
Epoch|Batch:  1 | 31
Epoch|Batch:  2 | 0
Epoch|Batch:  2 | 1
Epoch|Batch:  2 | 2
Epoch|Batch:  2 | 3
Epoch|Batch:  2 | 4
Epoch|Batch:  2 | 5
Epoch|Batch:  2 | 6
Epoch|Batch:  2 | 7
Epoch|Batch:  2 | 8
Epoch|Batch:  2 | 9
Epoch|Batch:  2 | 10
Epoch|Batch:  2 | 11
Epoch|Batch:  2 | 12
Epoch|Batch:  2 | 13
Epoch|Batch:  2 | 14
Epoch|Batch:  2 | 15
Epoch|Batch:  2 | 16
Epoch|Batch:  2 | 17
Epoch|Batch:  2 | 18
Epoch|Batch:  2 | 19
Epoch|Batch:  2 | 20
Epoch|Batch:  2 | 21
Epoch|Batch:  2 | 22
Epoch|Batch:  2 | 23
Epoch|Batch:  2 | 24
Epoch|Batch:  2 | 25
Epoch|Batch:  2 | 26
Epoch|Batch:  2 | 27
Epoch|Batch:  2 | 28
Epoch|Batch:  2 | 29
Epoch|Batch:  2 | 30
Epoch|Batch:  2 | 31
Updated policy and critic!
Update:  2
rollout steps: 12800 time taken overall 1.1920928955078125e-06 time taken per step: 7.450580596923828e-11
Epoch|Batch:  0 | 0
Epoch|Batch:  0 | 1
Epoch|Batch:  0 | 2
Epoch|Batch:  0 | 3
Epoch|Batch:  0 | 4
Epoch|Batch:  0 | 5
Epoch|Batch:  0 | 6
Epoch|Batch:  0 | 7
Epoch|Batch:  0 | 8
Epoch|Batch:  0 | 9
Epoch|Batch:  0 | 10
Epoch|Batch:  0 | 11
Epoch|Batch:  0 | 12
Epoch|Batch:  0 | 13
Epoch|Batch:  0 | 14
Epoch|Batch:  0 | 15
Epoch|Batch:  0 | 16
Epoch|Batch:  0 | 17
Epoch|Batch:  0 | 18
Epoch|Batch:  0 | 19
Epoch|Batch:  0 | 20
Epoch|Batch:  0 | 21
Epoch|Batch:  0 | 22
Epoch|Batch:  0 | 23
Epoch|Batch:  0 | 24
Epoch|Batch:  0 | 25
Epoch|Batch:  0 | 26
Epoch|Batch:  0 | 27
Epoch|Batch:  0 | 28
Epoch|Batch:  0 | 29
Epoch|Batch:  0 | 30
Epoch|Batch:  0 | 31
Epoch|Batch:  1 | 0
Epoch|Batch:  1 | 1
Epoch|Batch:  1 | 2
Epoch|Batch:  1 | 3
Epoch|Batch:  1 | 4
Epoch|Batch:  1 | 5
Epoch|Batch:  1 | 6
Epoch|Batch:  1 | 7
Epoch|Batch:  1 | 8
Epoch|Batch:  1 | 9
Epoch|Batch:  1 | 10
Epoch|Batch:  1 | 11
Epoch|Batch:  1 | 12
Epoch|Batch:  1 | 13
Epoch|Batch:  1 | 14
Epoch|Batch:  1 | 15
Epoch|Batch:  1 | 16
Epoch|Batch:  1 | 17
Epoch|Batch:  1 | 18
Epoch|Batch:  1 | 19
Epoch|Batch:  1 | 20
Epoch|Batch:  1 | 21
Epoch|Batch:  1 | 22
Epoch|Batch:  1 | 23
Epoch|Batch:  1 | 24
Epoch|Batch:  1 | 25
Epoch|Batch:  1 | 26
Epoch|Batch:  1 | 27
Epoch|Batch:  1 | 28
Epoch|Batch:  1 | 29
Epoch|Batch:  1 | 30
Epoch|Batch:  1 | 31
Epoch|Batch:  2 | 0
Epoch|Batch:  2 | 1
Epoch|Batch:  2 | 2
Epoch|Batch:  2 | 3
Epoch|Batch:  2 | 4
Epoch|Batch:  2 | 5
Epoch|Batch:  2 | 6
Epoch|Batch:  2 | 7
Epoch|Batch:  2 | 8
Epoch|Batch:  2 | 9
Epoch|Batch:  2 | 10
Epoch|Batch:  2 | 11
Epoch|Batch:  2 | 12
Epoch|Batch:  2 | 13
Epoch|Batch:  2 | 14
Epoch|Batch:  2 | 15
Epoch|Batch:  2 | 16
Epoch|Batch:  2 | 17
Epoch|Batch:  2 | 18
Epoch|Batch:  2 | 19
Epoch|Batch:  2 | 20
Epoch|Batch:  2 | 21
Epoch|Batch:  2 | 22
Epoch|Batch:  2 | 23
Epoch|Batch:  2 | 24
Epoch|Batch:  2 | 25
Epoch|Batch:  2 | 26
Epoch|Batch:  2 | 27
Epoch|Batch:  2 | 28
Epoch|Batch:  2 | 29
Epoch|Batch:  2 | 30
Epoch|Batch:  2 | 31
Updated policy and critic!
Update:  3
rollout steps: 19200 time taken overall 3.0994415283203125e-06 time taken per step: 4.9670537312825524e-11
Epoch|Batch:  0 | 0
Epoch|Batch:  0 | 1
Epoch|Batch:  0 | 2
Epoch|Batch:  0 | 3
Epoch|Batch:  0 | 4
Epoch|Batch:  0 | 5
Epoch|Batch:  0 | 6
Epoch|Batch:  0 | 7
Epoch|Batch:  0 | 8
Epoch|Batch:  0 | 9
Epoch|Batch:  0 | 10
Epoch|Batch:  0 | 11
Epoch|Batch:  0 | 12
Epoch|Batch:  0 | 13
Epoch|Batch:  0 | 14
Epoch|Batch:  0 | 15
Epoch|Batch:  0 | 16
Epoch|Batch:  0 | 17
Epoch|Batch:  0 | 18
Epoch|Batch:  0 | 19
Epoch|Batch:  0 | 20
Epoch|Batch:  0 | 21
Epoch|Batch:  0 | 22
Epoch|Batch:  0 | 23
Epoch|Batch:  0 | 24
Epoch|Batch:  0 | 25
Epoch|Batch:  0 | 26
Epoch|Batch:  0 | 27
Epoch|Batch:  0 | 28
Epoch|Batch:  0 | 29
Epoch|Batch:  0 | 30
Epoch|Batch:  0 | 31
Epoch|Batch:  1 | 0
Epoch|Batch:  1 | 1
Epoch|Batch:  1 | 2
Epoch|Batch:  1 | 3
Epoch|Batch:  1 | 4
Epoch|Batch:  1 | 5
Epoch|Batch:  1 | 6
Epoch|Batch:  1 | 7
Epoch|Batch:  1 | 8
Epoch|Batch:  1 | 9
Epoch|Batch:  1 | 10
Epoch|Batch:  1 | 11
Epoch|Batch:  1 | 12
Epoch|Batch:  1 | 13
Epoch|Batch:  1 | 14
Epoch|Batch:  1 | 15
Epoch|Batch:  1 | 16
Epoch|Batch:  1 | 17
Epoch|Batch:  1 | 18
Epoch|Batch:  1 | 19
Epoch|Batch:  1 | 20
Epoch|Batch:  1 | 21
Epoch|Batch:  1 | 22
Epoch|Batch:  1 | 23
Epoch|Batch:  1 | 24
Epoch|Batch:  1 | 25
Epoch|Batch:  1 | 26
Epoch|Batch:  1 | 27
Epoch|Batch:  1 | 28
Epoch|Batch:  1 | 29
Epoch|Batch:  1 | 30
Epoch|Batch:  1 | 31
Epoch|Batch:  2 | 0
Epoch|Batch:  2 | 1
Epoch|Batch:  2 | 2
Epoch|Batch:  2 | 3
Epoch|Batch:  2 | 4
Epoch|Batch:  2 | 5
Epoch|Batch:  2 | 6
Epoch|Batch:  2 | 7
Epoch|Batch:  2 | 8
Epoch|Batch:  2 | 9
Epoch|Batch:  2 | 10
Epoch|Batch:  2 | 11
Epoch|Batch:  2 | 12
Epoch|Batch:  2 | 13
Epoch|Batch:  2 | 14
Epoch|Batch:  2 | 15
Epoch|Batch:  2 | 16
Epoch|Batch:  2 | 17
Epoch|Batch:  2 | 18
Epoch|Batch:  2 | 19
Epoch|Batch:  2 | 20
Epoch|Batch:  2 | 21
Epoch|Batch:  2 | 22
Epoch|Batch:  2 | 23
Epoch|Batch:  2 | 24
Epoch|Batch:  2 | 25
Epoch|Batch:  2 | 26
Epoch|Batch:  2 | 27
Epoch|Batch:  2 | 28
Epoch|Batch:  2 | 29
Epoch|Batch:  2 | 30
Epoch|Batch:  2 | 31
Updated policy and critic!
Update:  4
rollout steps: 25600 time taken overall 3.814697265625e-06 time taken per step: 6.51925802230835e-11
Epoch|Batch:  0 | 0
Epoch|Batch:  0 | 1
Epoch|Batch:  0 | 2
Epoch|Batch:  0 | 3
Epoch|Batch:  0 | 4
Epoch|Batch:  0 | 5
Epoch|Batch:  0 | 6
Epoch|Batch:  0 | 7
Epoch|Batch:  0 | 8
Epoch|Batch:  0 | 9
Epoch|Batch:  0 | 10
Epoch|Batch:  0 | 11
Epoch|Batch:  0 | 12
Epoch|Batch:  0 | 13
Epoch|Batch:  0 | 14
Epoch|Batch:  0 | 15
Epoch|Batch:  0 | 16
Epoch|Batch:  0 | 17
Epoch|Batch:  0 | 18
Epoch|Batch:  0 | 19
Epoch|Batch:  0 | 20
Epoch|Batch:  0 | 21
Epoch|Batch:  0 | 22
Epoch|Batch:  0 | 23
Epoch|Batch:  0 | 24
Epoch|Batch:  0 | 25
Epoch|Batch:  0 | 26
Epoch|Batch:  0 | 27
Epoch|Batch:  0 | 28
Epoch|Batch:  0 | 29
Epoch|Batch:  0 | 30
Epoch|Batch:  0 | 31
Epoch|Batch:  1 | 0
Traceback (most recent call last):
  File "/Users/stav.42/RL_Library/cartpole/ppo/tparallel.py", line 436, in <module>
    print("Start training")
  File "/Users/stav.42/RL_Library/cartpole/ppo/tparallel.py", line 412, in train
    self.get_td_buffer()
  File "/Users/stav.42/RL_Library/cartpole/ppo/tparallel.py", line 250, in policy_update
    loss_pol.backward(retain_graph=True)
  File "/Users/stav.42/miniconda3/envs/pytorch_RL/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/Users/stav.42/miniconda3/envs/pytorch_RL/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt